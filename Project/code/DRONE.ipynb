{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103805, 19)\n",
      "(103802, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index        0\n",
       "Bug ID       0\n",
       "Product      0\n",
       "Component    0\n",
       "Assignee     0\n",
       "Summary      0\n",
       "Priority     0\n",
       "Severity     0\n",
       "TMP1         0\n",
       "TMP2         0\n",
       "TMP3         0\n",
       "TMP4         0\n",
       "TMP5         0\n",
       "TMP6         0\n",
       "TMP7         0\n",
       "TMP8         0\n",
       "TMP9         0\n",
       "TMP10        0\n",
       "TMP11        0\n",
       "TMP12        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_with_temporal.csv')\n",
    "df.drop(['Keywords','Summary.1','Status','Resolution','Changed','Opened'],axis=1,inplace=True)\n",
    "print df.shape\n",
    "df.dropna(inplace=True)\n",
    "print df.shape\n",
    "df.reset_index(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies( df[['Product','Component','Assignee','Severity']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TMP1', u'TMP2', u'TMP3', u'TMP4', u'TMP5', u'TMP6', u'TMP7', u'TMP8',\n",
       "       u'TMP9', u'TMP10', u'TMP11', u'TMP12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_features = pd.concat([dummy_df, df[df.columns[9:]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103802, 357)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103802, 357)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_features.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')\n",
    "def tokenize_stop_stem(text):\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation) and stem\n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            token = token.lower()\n",
    "            if token not in stopwords:\n",
    "                if not re.search('[0-9]', token):\n",
    "                    try:\n",
    "                        token = stemmer.stem(token)\n",
    "                        filtered_tokens.append(token)\n",
    "                    except UnicodeDecodeError:\n",
    "                        print 'illeagal token ignored:',token\n",
    "                        pass\n",
    "    except UnicodeDecodeError:\n",
    "        print 'illeagal token ignored:',token\n",
    "        pass\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sklearn countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countVect = CountVectorizer(input='content',lowercase=False, max_features=395996, tokenizer=tokenize_stop_stem, decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 s, sys: 36 ms, total: 16.6 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%time countVector = countVect.fit_transform(df.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<103802x17868 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 584285 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ctoi(x):\n",
    "    if x=='P1':\n",
    "        return 1 \n",
    "    if x=='P2':\n",
    "        return 2\n",
    "    if x=='P3':\n",
    "        return 3\n",
    "    if x=='P4':\n",
    "        return 4\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Priority_int'] = df['Priority'].apply(lambda x: ctoi(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make spare representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<103802x18225 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 2245117 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "other_sparse = sparse.csr_matrix(other_features.values)\n",
    "inputDF = sparse.hstack((other_features,countVector),format=\"csr\")\n",
    "inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51901, 18225)\n",
      "(51901, 18225)\n"
     ]
    }
   ],
   "source": [
    "training_ip = inputDF[0:103802/2]\n",
    "training_op = df['Priority_int'][0:103802/2]\n",
    "print training.shape\n",
    "validation_ip = inputDF[103802/2:]\n",
    "validation_op = df['Priority'][0:103802/2]\n",
    "print validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Linear Regression on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(training_ip, training_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_set_preds = lr.predict(validation_ip)\n",
    "validation_set_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 7 85 2\n"
     ]
    }
   ],
   "source": [
    "p1 = int((df['Priority']=='P1').sum()/float(df['Priority'].shape[0])*100)\n",
    "p2 = int((df['Priority']=='P2').sum()/float(df['Priority'].shape[0])*100)\n",
    "p3 = int((df['Priority']=='P3').sum()/float(df['Priority'].shape[0])*100)\n",
    "p4 = int((df['Priority']=='P4').sum()/float(df['Priority'].shape[0])*100)\n",
    "print p1,p2,p3,p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T0 = validation_set_preds.min()\n",
    "(T1,T2,T3,T4) = np.percentile(validation_set_preds,[p1,p2,p3,p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.06095495679443852,\n",
       " 2.2816289379769694,\n",
       " 2.4837134169093837,\n",
       " 3.1557069211757209,\n",
       " 2.1841227691038405)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T0,T1,T2,T3,T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to map regression output to class labels according to threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get class label based on threhsolds for a single test sample\n",
    "def itoc(x, T):\n",
    "    if x <= T['T1']:\n",
    "        return 'P1'\n",
    "    if x <= T['T2']:\n",
    "        return 'P2'\n",
    "    if x <= T['T3']:\n",
    "        return 'P3'\n",
    "    if x <= T['T4']:\n",
    "        return 'P4'\n",
    "    return 'P5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get f1 score for given set of thresholds\n",
    "def F1ScoreTH(T, val_preds, actual_labels):\n",
    "    val_class_preds = val_preds.map(lambda x: itoc(x, T))\n",
    "    return f1_score(actual_labels, val_class_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_set_class_preds = [itoc(x) for x in validation_set_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1851364049520588"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(validation_op, validation_set_class_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(T, t, actual, preds):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c8c7cf1931d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'T0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T4'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'T0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimize_thresholds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T0' is not defined"
     ]
    }
   ],
   "source": [
    "T = {'T0': T0, 'T1': T1, 'T2': T2, 'T3': T3, 'T4': T4}\n",
    "\n",
    "TH = ['T0', 'T1', 'T2', 'T3', 'T4']\n",
    "def optimize_thresholds(T, actual, preds):\n",
    "    for i in range(1, len(TH)+1):\n",
    "        D = T[TH[i]] - T[TH[i-1]]\n",
    "        while (True):\n",
    "            f1_v0 = F1ScoreTH(T, preds, actual)\n",
    "            delta = (0.01*D)\n",
    "\n",
    "            if (T[TH[i]] + delta < T[TH[i+1]]):\n",
    "                T[TH[i]] += deta\n",
    "                f1_v1 = F1ScoreTH(T, preds, actual)\n",
    "                T[TH[i]] -= deta\n",
    "            else:\n",
    "                f1_v1 = f1_v0\n",
    "            \n",
    "            if (T[TH[i]] - delta > T[TH[i-1]]):\n",
    "                T[TH[i]] -= deta\n",
    "                f1_v2 = F1ScoreTH(T, preds, actual)\n",
    "                T[TH[i]] += deta\n",
    "            else:\n",
    "                f1_v2 = f1_v0\n",
    "            \n",
    "            if (f1_v1 > f1_v0 and f1_v1 > f1_v2):\n",
    "                T[TH[i]] += delta\n",
    "            elif (f1_v1 > f1_v0 and f1_v2 > f1_v1):\n",
    "                T[TH[i]] -= delta\n",
    "            elif (f1_v1 < f1_v0 and f1_v2 > f1_v0):\n",
    "                T[TH[i]] -= delta\n",
    "            else:\n",
    "                break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
