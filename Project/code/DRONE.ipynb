{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from data_preprocessing import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/processed/train_processed.csv')\n",
    "test_df = pd.read_csv('../data/processed/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed nan values\n",
      "count vectorizer finished fitting\n",
      "count vector finished transforming\n",
      "dummy variables created\n",
      "created a sparse matrix of all features\n"
     ]
    }
   ],
   "source": [
    "p = DataProcessor()\n",
    "train_processed, train_original = p.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count vector finished transforming\n",
      "dummy variables created\n",
      "created a sparse matrix of all features\n"
     ]
    }
   ],
   "source": [
    "test_processed, test_original = p.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<83041x15940 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 3359482 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sklearn countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctoi(x):\n",
    "    if x=='P1':\n",
    "        return 1 \n",
    "    if x=='P2':\n",
    "        return 2\n",
    "    if x=='P3':\n",
    "        return 3\n",
    "    if x=='P4':\n",
    "        return 4\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Priority_int = train_original['Priority'].apply(lambda x: ctoi(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make spare representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41520, 15940)\n",
      "(41521, 15940)\n",
      "(20761, 15940)\n"
     ]
    }
   ],
   "source": [
    "training_ip = train_processed[0:83041/2]\n",
    "training_op = Priority_int[0:83041/2]\n",
    "print training_ip.shape\n",
    "validation_ip = train_processed[83041/2:]\n",
    "validation_op = train_original['Priority'][83041/2:]\n",
    "print validation_ip.shape\n",
    "\n",
    "test_ip = test_processed\n",
    "test_op = test_original['Priority']\n",
    "print test_ip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Linear Regression on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LinearRegression(n_jobs=-1)\n",
    "lr = RandomForestRegressor(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(training_ip, training_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.4  3.   3.  ...,  2.5  3.   2.9]\n",
      "(41521,)\n",
      "(41521, 1)\n"
     ]
    }
   ],
   "source": [
    "validation_set_preds = lr.predict(validation_ip)\n",
    "print validation_set_preds\n",
    "print validation_set_preds.shape\n",
    "validation_set_preds = validation_set_preds.reshape(validation_set_preds.shape[0], 1)\n",
    "print validation_set_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 7 85 2\n"
     ]
    }
   ],
   "source": [
    "# Finding percentile of each class in training data\n",
    "p1 = int((train_original['Priority']=='P1').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "p2 = int((train_original['Priority']=='P2').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "p3 = int((train_original['Priority']=='P3').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "p4 = int((train_original['Priority']=='P4').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "print p1,p2,p3,p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Thresholds based on these percentiles\n",
    "T0 = validation_set_preds.min()\n",
    "(T1,T2,T3,T4) = np.percentile(validation_set_preds,[p1,p2,p3,p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 2.1000000000000001, 2.5, 3.0, 2.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T0,T1,T2,T3,T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map regression output to class labels according to threshold\n",
    "T = {'T0': T0, 'T1': T1, 'T2': T2, 'T3': T3, 'T4': T4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get class label based on threhsolds for a single test sample\n",
    "def itoc(x, T):\n",
    "    if x <= T['T1']:\n",
    "        return 'P1'\n",
    "    if x <= T['T2']:\n",
    "        return 'P2'\n",
    "    if x <= T['T3']:\n",
    "        return 'P3'\n",
    "    if x <= T['T4']:\n",
    "        return 'P4'\n",
    "    return 'P5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33075243555700173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating F1 Score before tweaking thresholds\n",
    "from sklearn.metrics import f1_score\n",
    "validation_set_class_preds = [itoc(x, T) for x in validation_set_preds]\n",
    "f1_score(validation_op, validation_set_class_preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Tweaking (Greedy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get f1 score for given set of thresholds\n",
    "def F1ScoreTH(T, val_preds, actual_labels):\n",
    "    val_class_preds = np.apply_along_axis(lambda x: itoc(x, T), 1, val_preds)\n",
    "#     val_class_preds = val_preds.map(lambda x: itoc(x, T))\n",
    "    return f1_score(actual_labels, val_class_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = ['T0', 'T1', 'T2', 'T3', 'T4']\n",
    "def optimize_thresholds(T, actual, preds, delta):\n",
    "    for i in range(1, len(TH)):\n",
    "        D = T[TH[i]] - T[TH[i-1]]\n",
    "        while (True):\n",
    "            f1_v0 = F1ScoreTH(T, preds, actual)\n",
    "            delta = (delta*D)\n",
    "\n",
    "            if (i + 1 < len(TH) and T[TH[i]] + delta < T[TH[i+1]]):\n",
    "                T[TH[i]] += delta\n",
    "                f1_v1 = F1ScoreTH(T, preds, actual)\n",
    "                T[TH[i]] -= delta\n",
    "            else:\n",
    "                f1_v1 = f1_v0\n",
    "            \n",
    "            if (T[TH[i]] - delta > T[TH[i-1]]):\n",
    "                T[TH[i]] -= delta\n",
    "                f1_v2 = F1ScoreTH(T, preds, actual)\n",
    "                T[TH[i]] += delta\n",
    "            else:\n",
    "                f1_v2 = f1_v0\n",
    "                \n",
    "#             print \"----- handling TH for \", TH[i], \"------\"\n",
    "#             print f1_v0, f1_v1, f1_v2\n",
    "            \n",
    "            if (f1_v1 > f1_v0 and f1_v1 > f1_v2):\n",
    "                T[TH[i]] += delta\n",
    "#                 print \"increasing threshold for \", TH[i]\n",
    "            elif (f1_v1 > f1_v0 and f1_v2 > f1_v1):\n",
    "                T[TH[i]] -= delta\n",
    "#                 print \"increasing threshold for \", TH[i]\n",
    "            elif (f1_v1 < f1_v0 and f1_v2 > f1_v0):\n",
    "                T[TH[i]] -= delta\n",
    "#                 print \"decreasing threshold for \", TH[i]\n",
    "            else:\n",
    "                break;\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T0': 1.0, 'T1': 2.1000000000000001, 'T2': 2.5, 'T3': 3.0, 'T4': 2.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = {'T0': T0, 'T1': T1, 'T2': T2, 'T3': T3, 'T4': T4}\n",
    "T_new = deepcopy(T)\n",
    "T_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T0': 1.0, 'T1': 2.1000000000000001, 'T2': 2.5, 'T3': 3.0, 'T4': 2.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_thresholds(T_new, validation_op, validation_set_preds, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T0': 1.0, 'T1': 2.1000000000000001, 'T2': 2.5, 'T3': 3.0, 'T4': 2.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T0': 1.0, 'T1': 2.1000000000000001, 'T2': 2.5, 'T3': 3.0, 'T4': 2.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33075243555700173"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1ScoreTH(T, validation_set_preds, validation_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = int((train_original['Priority']=='P1').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "p2 = int((train_original['Priority']=='P2').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "p3 = int((train_original['Priority']=='P3').sum()/float(train_original['Priority'].shape[0])*100)\n",
    "p4 = int((train_original['Priority']=='P4').sum()/float(train_original['Priority'].shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 7 85 2\n"
     ]
    }
   ],
   "source": [
    "print p1,p2,p3,p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 25s, sys: 416 ms, total: 3min 26s\n",
      "Wall time: 41.6 s\n",
      "0.316226153864\n",
      "CPU times: user 3min 31s, sys: 136 ms, total: 3min 31s\n",
      "Wall time: 41.9 s\n",
      "0.310936724414\n",
      "CPU times: user 3min 27s, sys: 456 ms, total: 3min 28s\n",
      "Wall time: 41.2 s\n",
      "0.319906051442\n",
      "CPU times: user 3min 48s, sys: 492 ms, total: 3min 48s\n",
      "Wall time: 47.7 s\n",
      "0.32398468925\n",
      "CPU times: user 4min 14s, sys: 236 ms, total: 4min 15s\n",
      "Wall time: 51.7 s\n",
      "0.335277481449\n",
      "CPU times: user 3min 52s, sys: 204 ms, total: 3min 52s\n",
      "Wall time: 46.8 s\n",
      "0.333555468179\n",
      "CPU times: user 4min 59s, sys: 220 ms, total: 4min 59s\n",
      "Wall time: 1min\n",
      "0.327226538537\n",
      "CPU times: user 3min 55s, sys: 168 ms, total: 3min 56s\n",
      "Wall time: 47.7 s\n",
      "0.329626601626\n",
      "CPU times: user 4min 39s, sys: 964 ms, total: 4min 40s\n",
      "Wall time: 56.9 s\n",
      "0.315655930949\n",
      "CPU times: user 3min 39s, sys: 1.03 s, total: 3min 40s\n",
      "Wall time: 44.3 s\n",
      "0.333107442796\n"
     ]
    }
   ],
   "source": [
    "cvscores = []\n",
    "average_f1_scores = []\n",
    "lr = RandomForestRegressor(n_jobs=-1)\n",
    "for train,val in kf.split(train_processed, Priority_int):\n",
    "    train_input = train_processed[train]\n",
    "    val_input = train_processed[val]\n",
    "    train_output = Priority_int[train]\n",
    "    val_output = train_original['Priority'][val]\n",
    "    \n",
    "    vlen = len(Priority_int)\n",
    "    vtraining_ip = train_input[0:vlen/2]\n",
    "    vtraining_op = train_output[0:vlen/2]\n",
    "\n",
    "    vvalidation_ip = train_input[vlen/2:]\n",
    "    vvalidation_op = train_original['Priority'][train][vlen/2:]#train_output[vlen/2:]\n",
    "    \n",
    "    %time lr.fit(vtraining_ip,vtraining_op)\n",
    "    \n",
    "    val_prediction = lr.predict(vvalidation_ip)\n",
    "    val_prediction = val_prediction.reshape(val_prediction.shape[0], 1)\n",
    "    \n",
    "    vT0 = val_prediction.min()\n",
    "    (vT1,vT2,vT3,vT4) = np.percentile(val_prediction,[p1,p2,p3,p4])\n",
    "    vT = {'T0': vT0, 'T1': vT1, 'T2': vT2, 'T3': vT3, 'T4': vT4}\n",
    "    \n",
    "    vT_new = optimize_thresholds(vT, vvalidation_op, val_prediction, 0.01)\n",
    "    \n",
    "    val_prediction = lr.predict(val_input)\n",
    "    val_prediction = val_prediction.reshape(val_prediction.shape[0], 1)\n",
    "    \n",
    "    val_class_preds = np.apply_along_axis(lambda x: itoc(x, vT_new), 1, val_prediction)\n",
    "    scores = f1_score(val_output, val_class_preds, average=None)\n",
    "    print np.mean(scores)\n",
    "    cvscores.append(scores)\n",
    "    average_f1_scores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.324550308251 0.00811135543327\n"
     ]
    }
   ],
   "source": [
    "print np.mean(cvscores), np.std(average_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.33504274,  0.18518519,  0.88443226,  0.        ,  0.17647059]),\n",
       " array([ 0.29554656,  0.1986234 ,  0.88251366,  0.        ,  0.178     ]),\n",
       " array([ 0.32825719,  0.20171674,  0.88564828,  0.        ,  0.18390805]),\n",
       " array([ 0.36135957,  0.21353066,  0.88805648,  0.        ,  0.15697674]),\n",
       " array([ 0.36291913,  0.24758221,  0.88941548,  0.        ,  0.17647059]),\n",
       " array([ 0.36174636,  0.2509434 ,  0.8861015 ,  0.        ,  0.16898608]),\n",
       " array([ 0.33333333,  0.24876604,  0.88703531,  0.        ,  0.16699801]),\n",
       " array([ 0.33221477,  0.24279835,  0.8885045 ,  0.        ,  0.18461538]),\n",
       " array([ 0.32881356,  0.18796199,  0.88257767,  0.        ,  0.17892644]),\n",
       " array([ 0.39677419,  0.21107628,  0.88584409,  0.        ,  0.17184265])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Evolution  - Parameter tuning for threshold change delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (validation_op,validation_set_preds)\n",
    "bounds = [ (0.01,0.10) ] # order: percentage shift in threhsold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(parameters, *args):\n",
    "    #print args[0], args[1]\n",
    "    parameters = map(float,parameters)\n",
    "    T = {'T0': T0, 'T1': T1, 'T2': T2, 'T3': T3, 'T4': T4}\n",
    "    T_new = optimize_thresholds(T, validation_op, validation_set_preds, parameters[0])\n",
    "    \n",
    "    f1 = F1ScoreTH(T_new, validation_set_preds, validation_op)\n",
    "    print f1, parameters\n",
    "    return -1*f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.330752435557 [0.08847658547469857]\n",
      "0.330752435557 [0.0457725393425509]\n",
      "0.337810575475 [0.09129733573351453]\n",
      "0.330752435557 [0.06925096047167976]\n",
      "0.330752435557 [0.07807642673240787]\n",
      "0.330752435557 [0.02643104309136409]\n",
      "0.330752435557 [0.058429377457218185]\n",
      "0.330752435557 [0.03348321886290703]\n",
      "0.330752435557 [0.016594290404370535]\n",
      "0.330752435557 [0.046029896126210765]\n",
      "0.330752435557 [0.06410965966777817]\n",
      "0.330752435557 [0.030937913154039133]\n",
      "0.330752435557 [0.03293310468917572]\n",
      "0.330752435557 [0.060931724948426635]\n",
      "0.330752435557 [0.08998310034159304]\n",
      "0.330752435557 [0.05205466786673592]\n",
      "0.330752435557 [0.039444211741080766]\n",
      "0.330752435557 [0.04333032049282347]\n",
      "0.330752435557 [0.060603724773334915]\n",
      "0.330752435557 [0.04847243261437668]\n",
      "0.337810575475 [0.09129733573351453]\n",
      "0.337810575475 [0.09129734573351453]\n",
      "CPU times: user 1min 20s, sys: 48 ms, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%time result = differential_evolution(func, bounds, args, strategy='rand2bin', popsize=10, mutation=(0.5,1.9), recombination=0.7, maxiter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09129734])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recalculating thresholds using this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = {'T0': T0, 'T1': T1, 'T2': T2, 'T3': T3, 'T4': T4}\n",
    "T_new = optimize_thresholds(T, validation_op, validation_set_preds, 0.0912)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running it finally on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   2.7  3.  ...,  3.   2.8  3. ]\n",
      "(20761,)\n",
      "(20761, 1)\n"
     ]
    }
   ],
   "source": [
    "test_set_preds = lr.predict(test_ip)\n",
    "print test_set_preds\n",
    "print test_set_preds.shape\n",
    "test_set_preds = test_set_preds.reshape(test_set_preds.shape[0], 1)\n",
    "print test_set_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33315309320563263"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "test_set_class_preds = [itoc(x, T) for x in test_set_preds]\n",
    "f1_score(test_op, test_set_class_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
