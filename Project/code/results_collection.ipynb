{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_preprocessing import DataProcessor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cv_results(clf,kf,inputDF,df):\n",
    "    \n",
    "    def print_pretty(title,scores):\n",
    "        print title,':'\n",
    "        print 'Average\\tStandard Deviation'\n",
    "        print np.mean(scores),'\\t',np.std(np.mean(scores,axis=1))\n",
    "        print 'CV mean scores:'\n",
    "        print np.mean(scores,axis=1)\n",
    "        print 'Mean per class:'\n",
    "        print 'P1\\tP2\\tP3\\tP4\\tP5'\n",
    "        for i in np.mean(scores,axis=0):\n",
    "            print i,\n",
    "        print\n",
    "        #print 'CV:'\n",
    "        #for f in scores:\n",
    "        #    print f\n",
    "        return\n",
    "    \n",
    "    cvscores = []\n",
    "    p_scores = []\n",
    "    r_scores = []\n",
    "    for train,test in kf.split(inputDF,df['Priority']):\n",
    "        train_input = inputDF[train]\n",
    "        test_input = inputDF[test]\n",
    "        train_output = df['Priority'][train]\n",
    "        test_output = df['Priority'][test]\n",
    "        clf.fit(train_input,train_output)\n",
    "        prediction = clf.predict(test_input)\n",
    "        scores = f1_score(test_output, prediction, average=None)\n",
    "        p_scores.append(precision_score(test_output, prediction, average=None))\n",
    "        r_scores.append(recall_score(test_output, prediction, average=None))\n",
    "        cvscores.append(scores)\n",
    "    print 'Cross-Validation Results'\n",
    "    print_pretty('F1 Scores',cvscores)\n",
    "    print ''\n",
    "    print_pretty('Precision Scores',p_scores)\n",
    "    print ''\n",
    "    print_pretty('Recall Scores',r_scores)\n",
    "    return cvscores, p_scores, r_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_result(clf, trainDF, df, testDF, df1):\n",
    "    \n",
    "    def print_pretty(title,score):\n",
    "        print title,':'\n",
    "        print 'Average:',np.mean(score)\n",
    "        print 'P1\\tP2\\tP3\\tP4\\tP5'\n",
    "        print score\n",
    "        return\n",
    "\n",
    "    clf.fit(trainDF, df['Priority'])\n",
    "    prediction = clf.predict(testDF)\n",
    "    f1 = f1_score(df1['Priority'], prediction, average=None)\n",
    "    p = precision_score(df1['Priority'], prediction, average=None)\n",
    "    r = recall_score(df1['Priority'], prediction, average=None)\n",
    "    tempdf = pd.DataFrame()\n",
    "    tempdf['F1'] = f1\n",
    "    tempdf['Precision'] = p\n",
    "    tempdf['Recall'] = r\n",
    "    print tempdf\n",
    "    print list(tempdf.mean(axis=0))\n",
    "    #print 'TEST RESULTS:'\n",
    "    #print_pretty('F1',f1)\n",
    "    #print ''\n",
    "    #print_pretty('Precision',p)\n",
    "    #print ''\n",
    "    #print_pretty('Recall',r)\n",
    "    return f1,p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/processed/train_processed.csv')\n",
    "df_test = pd.read_csv('../data/processed/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed nan values\n",
      "count vectorizer finished fitting\n",
      "count vector finished transforming\n",
      "dummy variables created\n",
      "created a sparse matrix of all features\n",
      "count vector finished transforming\n",
      "dummy variables created\n",
      "created a sparse matrix of all features\n"
     ]
    }
   ],
   "source": [
    "p = DataProcessor()\n",
    "inputDF, df = p.fit_transform(df_train)\n",
    "testDF, df1 = p.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=19, min_samples_split=13, min_samples_leaf=1, class_weight=\"balanced\", n_jobs=-1)\n",
    "#nb = MultinomialNB()\n",
    "#svc = SVC()\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results\n",
      "F1 Scores :\n",
      "Average\tStandard Deviation\n",
      "0.496118087028 \t0.0125687086021\n",
      "CV mean scores:\n",
      "[ 0.49608219  0.50431894  0.52555944  0.50603347  0.4889616   0.48112999\n",
      "  0.49097611  0.48307772  0.48756444  0.49747697]\n",
      "Mean per class:\n",
      "P1\t\tP2\tP3\t\tP4\t\tP5\n",
      "0.397073609118 0.339465637432 0.91706674256 0.3589847544 0.467999691631\n",
      "\n",
      "Precision Scores :\n",
      "Average\tStandard Deviation\n",
      "0.498147697259 \t0.0159003257469\n",
      "CV mean scores:\n",
      "[ 0.49424806  0.51984757  0.52397962  0.51996737  0.48576083  0.48119344\n",
      "  0.49264439  0.48081955  0.4870852   0.49593094]\n",
      "Mean per class:\n",
      "P1\t\tP2\tP3\t\tP4\t\tP5\n",
      "0.356397310414 0.356014362667 0.916147034047 0.386689727644 0.475490051523\n",
      "\n",
      "Recall Scores :\n",
      "Average\tStandard Deviation\n",
      "0.498034064625 \t0.0125699883324\n",
      "CV mean scores:\n",
      "[ 0.50104629  0.49521308  0.53006434  0.49687998  0.49565959  0.48271338\n",
      "  0.49139667  0.48857809  0.49050051  0.50828872]\n",
      "Mean per class:\n",
      "P1\t\tP2\tP3\t\tP4\t\tP5\n",
      "0.449097788429 0.324725842723 0.918001744279 0.336088009122 0.462256938571\n",
      "CPU times: user 4min 10s, sys: 500 ms, total: 4min 10s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%time f1, precision, recall = get_cv_results(rf,kf,inputDF,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         F1  Precision    Recall\n",
      "0  0.380686   0.347826  0.420402\n",
      "1  0.336700   0.348432  0.325733\n",
      "2  0.915330   0.914073  0.916592\n",
      "3  0.337963   0.377261  0.306080\n",
      "4  0.476923   0.472561  0.481366\n",
      "[0.48952051296992288, 0.49203053572221672, 0.49003451079498417]\n",
      "CPU times: user 24.6 s, sys: 40 ms, total: 24.6 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "%time _,_,_ = get_test_result(clf=rf,trainDF=inputDF,df=df,testDF=testDF,df1=df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
