{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import DataProcessor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(clf,kf,inputDF,df):\n",
    "    \n",
    "    def print_pretty(title,scores):\n",
    "        print title,':'\n",
    "        print 'Average\\tStandard Deviation'\n",
    "        print np.mean(scores),'\\t',np.std(scores)\n",
    "        print 'P1\\t\\tP2\\tP3\\t\\tP4\\t\\tP5'\n",
    "        print 'Mean:'\n",
    "        print np.mean(scores,axis=0)\n",
    "        print 'CV:'\n",
    "        for f in scores:\n",
    "            print f\n",
    "        return\n",
    "    \n",
    "    cvscores = []\n",
    "    p_scores = []\n",
    "    r_scores = []\n",
    "    for train,test in kf.split(inputDF):\n",
    "        train_input = inputDF[train]\n",
    "        test_input = inputDF[test]\n",
    "        train_output = df['Priority'][train]\n",
    "        test_output = df['Priority'][test]\n",
    "        clf.fit(train_input,train_output)\n",
    "        prediction = clf.predict(test_input)\n",
    "        scores = f1_score(test_output, prediction, average=None)\n",
    "        p_scores.append(precision_score(test_output, prediction, average=None))\n",
    "        r_scores.append(recall_score(test_output, prediction, average=None))\n",
    "        cvscores.append(scores)\n",
    "    print 'Cross-Validation Results'\n",
    "    print_pretty('F1 Scores',cvscores)\n",
    "    print ''\n",
    "    print_pretty('Precision Scores',p_scores)\n",
    "    print ''\n",
    "    print_pretty('Recall Scores',r_scores)\n",
    "    return cvscores, p_scores, r_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_result(clf, trainDF, df, testDF, df1):\n",
    "    \n",
    "    def print_pretty(title,score):\n",
    "        print title,':'\n",
    "        print 'Average:',np.mean(score)\n",
    "        print 'P1\\tP2\\tP3\\tP4\\tP5'\n",
    "        print score\n",
    "        return\n",
    "\n",
    "    clf.fit(trainDF, df['Priority'])\n",
    "    prediction = clf.predict(testDF)\n",
    "    f1 = f1_score(df1['Priority'], prediction, average=None)\n",
    "    p = precision_score(df1['Priority'], prediction, average=None)\n",
    "    r = recall_score(df1['Priority'], prediction, average=None)\n",
    "    print 'TEST RESULTS:'\n",
    "    print_pretty('F1',f1)\n",
    "    print ''\n",
    "    print_pretty('Precision',p)\n",
    "    print ''\n",
    "    print_pretty('Recall',r)\n",
    "    return f1,p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/processed/train_processed.csv')\n",
    "df_test = pd.read_csv('../data/processed/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed nan values\n",
      "count vectorizer finished fitting\n",
      "count vector finished transforming\n",
      "dummy variables created\n",
      "created a sparse matrix of all features\n",
      "count vector finished transforming\n",
      "dummy variables created\n",
      "created a sparse matrix of all features\n"
     ]
    }
   ],
   "source": [
    "p = DataProcessor()\n",
    "inputDF, df = p.fit_transform(df_train)\n",
    "testDF, df1 = p.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1)\n",
    "nb = MultinomialNB()\n",
    "svc = SVC()\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores :\n",
      "Average\tStandard Deviation\n",
      "0.206922714903 \t0.203746442485\n",
      "P1\t\tP2\tP3\t\tP4\t\tP5\n",
      "Mean:\n",
      "[ 0.1643758   0.09933404  0.60543734  0.12834093  0.03712546]\n",
      "CV:\n",
      "[ 0.15804598  0.09156194  0.60387023  0.12365931  0.04059329]\n",
      "[ 0.16285714  0.08830744  0.60404213  0.12228797  0.0244898 ]\n",
      "[ 0.16835017  0.12195122  0.6040446   0.1218593   0.03314002]\n",
      "[ 0.15882353  0.10403587  0.61451354  0.14303639  0.04278922]\n",
      "[ 0.17228104  0.10172414  0.60970544  0.14105793  0.02689076]\n",
      "[ 0.15194869  0.09411765  0.60151229  0.121673    0.05190592]\n",
      "[ 0.17552182  0.11330472  0.61178461  0.12475634  0.04848485]\n",
      "[ 0.16336634  0.09515718  0.59800475  0.11485643  0.04205607]\n",
      "[ 0.16839135  0.08591065  0.60072079  0.12659847  0.02975207]\n",
      "[ 0.1641719   0.09726962  0.60617505  0.14362416  0.03115265]\n",
      "\n",
      "Precision Scores :\n",
      "Average\tStandard Deviation\n",
      "0.243620796339 \t0.341869421559\n",
      "P1\t\tP2\tP3\t\tP4\t\tP5\n",
      "Mean:\n",
      "[ 0.09391629  0.10556979  0.92473778  0.07313659  0.02074354]\n",
      "CV:\n",
      "[ 0.09011469  0.10282258  0.92663755  0.07035176  0.0226087 ]\n",
      "[ 0.09344262  0.08955224  0.92074053  0.06981982  0.01386322]\n",
      "[ 0.09673853  0.12302285  0.93015134  0.06850282  0.01862197]\n",
      "[ 0.09005003  0.125       0.92342598  0.08231047  0.02389381]\n",
      "[ 0.09835165  0.10805861  0.92760701  0.08133624  0.01481481]\n",
      "[ 0.08715337  0.0952381   0.92231884  0.06862044  0.02909091]\n",
      "[ 0.10059815  0.12021858  0.92053167  0.07074429  0.02737048]\n",
      "[ 0.09343148  0.09859155  0.92804482  0.06451613  0.02341717]\n",
      "[ 0.09587574  0.09140768  0.92656524  0.07189542  0.01643836]\n",
      "[ 0.09340659  0.10178571  0.92135476  0.08326848  0.01731602]\n",
      "\n",
      "Recall Scores :\n",
      "Average\tStandard Deviation\n",
      "0.381443956628 \t0.214346156117\n",
      "P1\t\tP2\tP3\t\tP4\t\tP5\n",
      "Mean:\n",
      "[ 0.65875593  0.09419987  0.4500753   0.52677524  0.17741344]\n",
      "CV:\n",
      "[ 0.64202335  0.08252427  0.4478683   0.51041667  0.19847328]\n",
      "[ 0.63333333  0.08709677  0.44944931  0.49206349  0.1048951 ]\n",
      "[ 0.64814815  0.1208981   0.44724321  0.55113636  0.15037594]\n",
      "[ 0.67219917  0.0890937   0.46047235  0.54545455  0.20454545]\n",
      "[ 0.69379845  0.09609121  0.45408522  0.53080569  0.14545455]\n",
      "[ 0.59230769  0.09302326  0.44628331  0.53631285  0.2406015 ]\n",
      "[ 0.68773234  0.10714286  0.45812808  0.52747253  0.21212121]\n",
      "[ 0.6496063   0.09195402  0.441127    0.52272727  0.20610687]\n",
      "[ 0.69111969  0.08103728  0.44442885  0.52941176  0.15652174]\n",
      "[ 0.67729084  0.09313725  0.45166737  0.52195122  0.15503876]\n",
      "CPU times: user 2.79 s, sys: 4 ms, total: 2.79 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%time f1, precision, recall = get_cv_results(nb,kf,inputDF,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS:\n",
      "F1 :\n",
      "Average: 0.210103322556\n",
      "P1\tP2\tP3\tP4\tP5\n",
      "[ 0.16997836  0.11461908  0.6032767   0.1261485   0.03649397]\n",
      "\n",
      "Precision :\n",
      "Average: 0.246429501152\n",
      "P1\tP2\tP3\tP4\tP5\n",
      "[ 0.09738503  0.12110225  0.92172505  0.0715493   0.02038588]\n",
      "\n",
      "Recall :\n",
      "Average: 0.386253721582\n",
      "P1\tP2\tP3\tP4\tP5\n",
      "[ 0.66769706  0.10879479  0.44836895  0.53249476  0.17391304]\n",
      "CPU times: user 356 ms, sys: 0 ns, total: 356 ms\n",
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%time _,_,_ = get_test_result(clf=nb,trainDF=inputDF,df=df,testDF=testDF,df1=df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
